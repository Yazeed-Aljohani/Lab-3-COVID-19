---
title: "Lab 02: COVID-19 Data Wrangling and Visualization"
author: "Yazeed Aljohani"
subtitle: "Data Wrangling and Visualization in R"
date: "`r Sys.Date()`"
format: 
  html:
    self-contained: true
    toc: true
execute:
  echo: true
output-dir: "docs"
theme: journal
editor: visual
---

# **Question 1: Public Data**

**Take a moment to reflect on the value of open data: How does easy access to historical and real-time environmental data shape our understanding of climate trends, resource management, and public health? What happens when this data disappears or becomes inaccessible? The role of independent archiving and collaborative stewardship has never been more critical in ensuring scientific progress and accountability.**

Open access to environmental and health data plays a crucial role in helping researchers, policymakers, and the public make informed decisions. Real-time and historical data offer valuable insights into climate trends, resource management, and public health. When this information disappears, transparency and trust are lost, and collaboration between scientists becomes more difficult. Without reliable data, it is harder to track long-term environmental changes or assess the effectiveness of policies. Thankfully, journalists, researchers, and scientists work to archive and protect these records. Platforms like The Internet Archive and Data Refuge help ensure that vital datasets remain available for future use. The New York Times COVID-19 data repository is a prime example of why independent data preservation matters. Its county-level records have been crucial for tracking the pandemic and informing public health responses. Maintaining open access to data is essential for scientific progress and accountability. Efforts to preserve information will support future research and responsible decision-making.

# **Question 2: Daily Summary**

```{r setup, include=FALSE}
# required libraries
library(tidyverse)  
library(flextable)  
library(zoo)        

```

```{r}

# 1- Reading in the data

data <- read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')

```

**Data Description:**

The dataset contains 2,502,832 rows and 6 columns, recording COVID-19 case data at the county level across the U.S.

### **Columns:** 

1.  **`date`** – The date of the recorded data.

2.  **`county`** – The name of the county.

3.  **`state`** – The state where the county is located.

4.  **`fips`** – A **5-digit code** identifying each county (first 2 digits = state, last 3 = county).

5.  **`cases`** – The **total** number of confirmed cases (cumulative).

6.  **`deaths`** – The **total** number of reported deaths (cumulative).

2.  **Create an object called `my.date` and set it as “2022-02-01” - ensure this is a `date` object:. Create a object called `my.state` and set it to “Colorado”.**

```{r}

# 2- Defining Date and State Variables

my.date <- as.Date("2022-02-01")
my.state <- "Colorado"

```

3.  **The URL based data read from Github is considered our “raw data”. Remember to always leave “raw-data-raw” and to generate meaningful subsets as you go.**

```{r}

# 3- Filtering for Colorado and Compute New Cases
colorado <- data |>
filter(state == my.state) |>
group_by(county) |>
arrange(date) |>
mutate(new_cases = cases - lag(cases),
new_deaths = deaths - lag(deaths)) |>
ungroup()
  

```

4.  **Using your subset, generate (2) tables. The first should show the 5 counties with the most CUMULATIVE cases, and the second should show the 5 counties with the most NEW cases. Remember to use your `my.date` object as a proxy for today’s date:**

```{r}
# 4- Finding the 5 Counties with the Most Cumulative Cases
filter (colorado, date == my.date) |>

slice_max(cases, n = 5) |>

select(Date = date, County = county, Cases = cases) |>

flextable() |>

add_header_lines("Most Cumulative Cases")
```

The table shows the five Colorado counties with the highest cumulative COVID-19 cases as of February 1, 2022. El Paso, Denver, Arapahoe, Adams, and Jefferson had the most confirmed cases

```{r}
# 4- Finding the 5 Counties with the Most New Cases

filter(colorado, date == my.date) |>
slice_max(cases, n = 5) |>
select(Date = date, County = county, Cases = new_cases) |>
flextable() |>
add_header_lines("Most New Cases")

```

The table displays the five Colorado counties with the highest new COVID-19 cases on February 1, 2022. El Paso, Denver, Arapahoe, Adams, and Jefferson reported the most new infections, indicating higher transmission rates in these areas on that date.

# **Question 3: Normalizing Data**

```{r}
# Define the URL
pop_url <- 'https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/counties/totals/co-est2023-alldata.csv'

# Read the population data
pop <- read.csv(pop_url)


```

1.  **Given the above URL, and guidelines on string concatenation and formatting, read in the population data and (1) create a five digit FIP variable and only keep columns that contain “NAME” or “2021” (remember the tidyselect option found with `?dplyr::select`). Additionally, remove all state level rows (e.g. COUNTY FIP == “000”)**

```{r}
# 1- filtering, and processing the data
pop <- read.csv(pop_url) |>
filter(COUNTY != 0) |>
mutate(fips = paste0(sprintf("%02d", STATE), sprintf("%03d", COUNTY))) |>
select(fips, contains('NAME'), contains('2021'))
```

2.  **Now, explore the data … what attributes does it have, what are the names of the columns? Do any match the COVID data we have? What are the dimensions… In a few sentences describe the data obtained after modification:**

```{r}
#| include: false
#Exploring the Data

glimpse(pop)  
dim(pop)      
names(pop)    
summary(pop)  

```

The dataset has 3,195 rows and 67 columns, providing county-level population estimates from the U.S. Census Bureau.

### **Key Details:**

-   **Geography:** It includes **state and county names** (`STNAME`, `CTYNAME`) and **FIPS codes** for identification.

-   **Population Estimates:** Covers **2020-2023** (`POPESTIMATE2020-2023`).

-   **Births & Deaths:** Tracks **annual births, deaths, and natural population changes**.

-   **Migration:** Includes **domestic and international migration** numbers per county.

-   **Growth Trends:** Shows **yearly population changes**.

### **How It Relates to COVID-19 Data:**

-   Both datasets **use FIPS codes**, so they can be **merged**.

-   **Population estimates help normalize COVID-19 data** (cases per capita).

-   **Annual data** means we’ll use **2021 estimates** for normalization.

3.  **What is the range of populations seen in Colorado counties in 2021:**

```{r}
range(filter(pop, STNAME == "Colorado")$POPESTIMATE2021, na.rm = TRUE)

```

The result \[1\] 741 737287 represents the range of populations seen in Colorado counties in 2021:

1.  741 – The smallest county population in Colorado in 2021.

2.   737287 – The largest county population in Colorado in 2021

4.  **Join the population data to the Colorado COVID data and compute the per capita cumulative cases, per capita new cases, and per capita new deaths:**

```{r}
# Merging COVID and population data

perCap <- inner_join(
  colorado, 
  select(pop, fips, pop = POPESTIMATE2021), 
  by = "fips"
) |>
  filter(date == my.date) |>
  mutate(
    cumPerCap = cases / pop,
    newCasesPerCap = new_cases / pop,
    newDeathsPerCap = new_deaths / pop
  )

```

5.  **Generate (2) new tables. The first should show the 5 counties with the most cumulative cases per capita on 2021-01-01, and the second should show the 5 counties with the most NEW cases per capita on the same date. Your tables should have clear column names and descriptive captions.**

```{r}

# 5- Top 5 Counties by Cumulative Cases per Capita

perCap |>
select(County = county, Cases = cumPerCap) |>
slice_max(Cases, n = 5) |>
flextable() |>
add_header_lines("Most Cummulitive Cases Per Capita")



```

The table ranks Colorado counties with the highest cumulative COVID-19 cases per capita as of February 1, 2022. Crowley, Bent, Pitkin, Lincoln, and Logan counties had the most infections relative to their populations

```{r}
# 5- Top 5 Counties by New Cases per Capitav
perCap |>
select(County = county, Cases = newCasesPerCap) |>
slice_max(Cases, n = 5) |>
flextable() |>
add_header_lines("Most New Cases Per Capita")

```

The table ranks Colorado counties with the highest new COVID-19 cases per capita on JFebruary 1, 2021. Crowley, Bent, Sedgwick, Washington, and Las Animas counties had the most new infections relative to their populations

# **Question 4: Rolling thresholds**

**Filter the merged COVID/Population data to only include the last 14 days. *Remember this should be a programmatic request and not hard-coded*. Then, use the `group_by`/`summarize` paradigm to determine the total number of new cases in the last 14 days per 100,000 people. Print a table of the top 5 counties, and, report the number that meet the watch list condition: “More than 100 new cases per 100,000 residents over the past 14 days…”**

```{r}

safe <- pop |>
inner_join(colorado, by = "fips") |>
filter(between(date, my.date - 13, my.date)) |>
group_by(county) |>
summarize(lag = sum(new_cases) / (POPESTIMATE2021[1]/100000)) |>
ungroup()
```

```{r}
safe |>
select(County = county, Cases = lag) |>
slice_max(Cases, n = 10) |>
flextable() |>
add_header_lines("Cases per 100,000 in the last 14 days")
```

The table ranks Colorado counties with the highest COVID-19 cases per 100,000 residents in the last 14 days before February 1, 2022. Crowley, Lincoln, and Alamosa counties had the highest infection rates.

# **Question 5: Death toll**

Given we are assuming it is February 1st, 2022. Your leadership has asked you to determine what percentage of deaths in each county were attributed to COVID last year (2021). You eagerly tell them that with the current Census data, you can do this!

From previous questions you should have a `data.frame` with daily COVID deaths in Colorado and the Census based, 2021 total deaths. For this question, you will find the ratio of total COVID deaths per county (2021) of all recorded deaths. In a plot of your choosing, visualize all counties where COVID deaths account for 20% or more of the annual death toll.

```{r}
x <- colorado |>
mutate(year = lubridate :: year(date)) |>
filter(year == 2021) |>
group_by(fips) |>
summarize(deaths = sum(new_deaths, na.rm = TRUE)) |>
left_join(pop, by = c("fips")) |>
mutate(death_ratio = 100 * (deaths / DEATHS2021)) |>
select(CTYNAME, deaths, DEATHS2021, death_ratio) |>
filter(death_ratio > 20)


ggplot(x, aes(x = death_ratio, y = reorder(CTYNAME, death_ratio))) +
  geom_col(fill = "red") +  
  theme_light() +
  labs(
    title = "Counties Where COVID Deaths Were >20% of Total Deaths (2021)",
    x = "COVID-19 Death Percentage (%)",
    y = "County"
  )
```

The bar chart displays Colorado counties where COVID-19 deaths accounted for more than 20% of total deaths in 2021. Conejos, Bent, and San Miguel counties had the highest percentages, exceeding 30-40%.

# **Question 6: Multi-state**

In this question, we are going to look at the story of 4 states and the impact scale can have on data interpretation. The states include: **New York**, **Colorado**, **Alabama**, and **Ohio**. Your task is to make a *faceted* bar plot showing the number of daily, **new** cases at the state level.

1.  First, we need to `group/summarize` our county level data to the state level, `filter` it to the four states of interest, and calculate the number of daily new cases (`diff/lag`) and the 7-day rolling mean.

    ```{r}
    library(tidyverse)
    library(zoo)

    state_covid <- data |>
      filter(state %in% c("New York", "Ohio", "Colorado", "Alabama")) |>  
      group_by(date, state) |>
       summarise(cases = sum(cases, na.rm = TRUE), .groups = "drop") |>  
      arrange(state, date) |>  
      group_by(state) |>  
      mutate(
        newCases = cases - lag(cases, default = 0), 
        roll = zoo::rollmean(newCases, k = 7, align = "right", fill = NA)  
      ) |>
      ungroup()
    ```

2.  **Using the modified data, make a facet plot of the daily new cases and the 7-day rolling mean. Your plot should use compelling geoms, labels, colors, and themes.**

```{r}
library(ggplot2)

ggplot(state_covid, aes(x = date)) +
  geom_col(aes(y = newCases), fill = "lightblue", col = "purple") +  
  geom_line(aes(y = roll), color = "darkblue", size = 1) +  
  theme_linedraw() +  
  facet_wrap(~state, nrow = 2, scales = "free_y") +   
  labs(
    title = "Cumulative COVID-19 Cases",
    x = "Date",
    y = "Case Count"
  )

```

The facted plot displays daily new COVID-19 cases and 7-day rolling averages for Alabama, Colorado, New York, and Ohio. Peaks in cases align with major COVID-19 waves, showing significant surges in late 2020 and early 2022, with New York experiencing the highest spikes.

3.  **The story of raw case counts can be misleading. To understand why, lets explore the cases per capita of each state. To do this, join the state COVID data to the population estimates and calculate the** newcases/totalpopulation**. Additionally, calculate the 7-day rolling mean of the new cases per capita counts. This is a tricky task and will take some thought, time, and modification to existing code (most likely)!**

```{r}
library(tidyverse)
library(zoo)

state_pop <- pop |>
  group_by(STNAME) |>
  summarise(state_pop = sum(POPESTIMATE2021, na.rm = TRUE))  

state_covid_per_capita <- state_covid |>
  inner_join(state_pop, by = c("state" = "STNAME")) |>  
  mutate(
    perCap = newCases / state_pop,  
    roll = zoo::rollmean(perCap, k = 7, align = "right", fill = NA)  
  ) |>
  ungroup()

```

```{r}

library(ggplot2)

# Plot the 7-day rolling average per capita
ggplot(state_covid_per_capita, aes(x = date, y = roll, color = state)) +
  geom_line(size = 1.2) +  # Line graph for rolling average
  theme_linedraw() +  # Better grid theme
  labs(
    title = "COVID-19 Cases Per Capita (7-Day Rolling Average)",
    subtitle = "Comparing New York, Ohio, Colorado, and Alabama",
    x = "Date",
    y = "Cases Per 100,000 People",
    color = "State"
  ) +
  scale_color_manual(values = c("New York" = "blue", "Ohio" = "purple", 
                                "Colorado" = "red", "Alabama" = "green")) +
  theme(
    text = element_text(size = 14),
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.position = "top"
  )

```

The graph shows the 7-day rolling average of COVID-19 cases per 100,000 people for New York, Ohio, Colorado, and Alabama. Major surges occurred in late 2020 and early 2022, with New York peaking highest.

5.  **Briefly describe the influence scaling by population had on the analysis? Does it make some states look better? Some worse? How so?**

Scaling by population allows for a fair comparison of COVID-19 severity across states. Initially, New York appeared worst due to its high total cases, while smaller states seemed less affected. After adjusting per capita, Alabama and Colorado showed comparable or even higher infection rates, revealing that outbreaks were more intense relative to their population sizes. This adjustment prevents misleading conclusions and highlights hidden trends in smaller states, making the analysis more accurate.

# **Question 7: Space & Time**

```{r}
library(tidyverse)
library(ggplot2)
library(maps)

# Step 1: Read in county centroid data and join with COVID-19 data
covid_geo <- read_csv('https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv') |>
  inner_join(data, by = "fips")  # Join on FIPS code

# Step 2: Compute Weighted Mean Center
meta <- covid_geo |>
  group_by(date) |>
  summarise(
    wmX_c = sum(LON * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE),  # Weighted Longitude
    wmY_c = sum(LAT * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE),  # Weighted Latitude
    cases = sum(cases, na.rm = TRUE)  # Total cases per day
  ) |>
  arrange(date) |>
  mutate(d = row_number())  # Add an index column for ordering

# Step 3: Plot the Weighted Mean Center Over Time
ggplot(meta) +
  borders("state", fill = "gray90", colour = "white") +  # Add state borders
  geom_point(aes(x = wmX_c, y = wmY_c, size = cases), color = "red", alpha = 0.5) +  # Plot weighted centers
  theme_linedraw() +
  labs(
    color = "Time",
    size = "Total Cases",
    x = "Longitude",
    y = "Latitude",
    title = "Weighted Center of COVID-19 Cases in the USA"
  ) +
  theme(legend.position = "right")  # Show legend for size

```

The COVID-19 weighted mean center was initially concentrated in the Northeast, where early outbreaks in New York and New Jersey fueled a surge in cases. Over time, it gradually shifted west and south, reflecting the spread of the virus into the Midwest and Southern states. This movement was influenced by population density, travel patterns, and changing public health policies. As the pandemic evolved, major waves like Delta and Omicron caused rapid shifts, highlighting how different regions experienced surges at different times.

```{r}
library(tidyverse)
library(ggplot2)
library(patchwork)

# Load county centroid data and merge with COVID data
meta <- read_csv('https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv') %>%
  inner_join(data, by = "fips") %>%
  group_by(date) %>%
  summarise(
    wmx_c = sum(LON * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE),  # Weighted mean X for cases
    WMY_c = sum(LAT * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE),  # Weighted mean Y for cases
    cases = sum(cases, na.rm = TRUE),  # Total cases
    wmx_d = sum(LON * deaths, na.rm = TRUE) / sum(deaths, na.rm = TRUE),  # Weighted mean X for deaths
    WMY_d = sum(LAT * deaths, na.rm = TRUE) / sum(deaths, na.rm = TRUE),  # Weighted mean Y for deaths
    deaths = sum(deaths, na.rm = TRUE)  # Total deaths
  ) %>%
  arrange(date) %>%
  mutate(d = row_number())  # Add index for ordering

# Plot Weighted Mean Center for Cases
p1 <- ggplot(meta) +
  borders("state", fill = "gray98", colour = "white") +
  geom_point(aes(x = wmx_c, y = WMY_c, size = cases), color = "red", alpha = 0.25) +
  theme_linedraw() +
  labs(
    color = "Time",
    size = "Cases",
    x = "",
    y = "",
    title = "Weighted Center of COVID-19 Cases"
  ) +
  theme(legend.position = "right")

# Plot Weighted Mean Center for Deaths
p2 <- ggplot(meta) +
  borders("state", fill = "gray98", colour = "white") +
  geom_point(aes(x = wmx_d, y = WMY_d, size = deaths), color = "navy", alpha = 0.25) +
  theme_linedraw() +
  labs(
    color = "Time",
    size = "Deaths",
    x = "",
    y = "",
    title = "Weighted Center of COVID-19 Deaths"
  ) +
  theme(legend.position = "right")

# Combine both plots side by side
p1 + p2

```
